{
    "datasource_id": "Meta reveals new \u2018Voicebox\u2019 AI that is too risky to release@Yahoo Finance@2023-06-19 20:42:10.624107@Meta",
    "data": "CANAD\u00c1-META (AP)\n\nMeta has created a new system that it says can generate convincing speech in a variety of styles \u2013 but will not release it for fear of the risks.\n\nThe new tool is called \u201cVoicebox\u201d and can be set to create outputs in different styles, new voices from scratch as well as with a sample. It makes speech across six languages, as well as a variety of other tools such as noise removal.\n\nIt says that it is a major development on previous speech systems that required specific training for each task. Instead, Voicebox can just be given raw audio and a transcription, and then be used to modify an audio sample.\n\nIt is far more effective than its competitors, Meta claimed in its announcement. It can generate words with a 5.9 per cent error rate compared to 1.9 per cent from competitor Vall-E, for instance, and do so as much as 20 times more quickly.\n\nMeta said that it had been built on the foundation of a new model it called \u201cFlow Matching\u201d. That allows the system to learn from speech that has not been carefully labelled, so that it can be trained on more and more diverse data.\n\nVoicebox was trained on 50,000 hours of speech and transcripts that came from public domain audiobooks in English, French, Spanish, German, Polish, and Portuguese, Meta said. Now that it has been trained, it can be given an audio recording and fill in the speech from the context, Meta said.\n\nThat could be used to create a realistic sounding voice from just two seconds of speech, for instance, potentially being used to bring voices to people who cannot speak or to add people\u2019s voices into games. It could also be used to translate a passage of speech from one lanagueg to another in a way that keeps the style, Meta said, allowing people to talk to each other authentically even if they don\u2019t speak the same language.\n\nIt could also be useful in more technical scenarios, such as audio editing, where it can be used to replace words that were not properly recorded, for instance.\n\nBut Meta said that the risks were such that it would not be releasing the model. It did not point to specific harms, but said that \u201cas with other powerful new AI innovations, we recognize that this technology brings the potential for misuse and unintended harm\u201d.\n\nNumerous reports have warned that such systems could be used to copy people\u2019s voices without their consent and in ways that could be harmful, such as creating fake videos of news events or using people\u2019s voices to pose as them during scam calls, for instance.\n\n\u201cThere are many exciting use cases for generative speech models, but because of the potential risks of misuse, we are not making the Voicebox model or code publicly available at this time,\u201d Meta said in a statement. \u201cWhile we believe it is important to be open with the AI community and to share our research to advance the state of the art in AI, it\u2019s also necessary to strike the right balance between openness with responsibility.\u201d\n\nIt also pointed to a separate paper, published on its website, in which it detailed how it had built a \u201chighly effective\u201d system that can distinguish between authentic speech and audio that had been generated with Voicebox."
}